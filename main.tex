%%%%%%%%%%%%%
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
%\documentclass[runningheads]{llncs}
%\documentclass[10pt,letterpaper,twocolumn]{article}
\documentclass{sig-alternate}


% packages
\usepackage{xspace}
\usepackage{ifthen}
\usepackage{amsbsy}
\usepackage{amssymb}
\usepackage{balance}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{needspace}
\usepackage{microtype}
\usepackage{bold-extra}
\usepackage{subfigure}
\usepackage{wrapfig}


% constants
\newcommand{\Title}{The Hidden Face of Execution Sampling}
\newcommand{\TitleShort}{\Title}
\newcommand{\Authors}{Alexandre Bergel, Vanessa Pe\~na, Juan Pablo Sandoval}
\newcommand{\AuthorsShort}{A. Bergel, V. Pe\~na, J.P. Sandoval}

% references
\usepackage[colorlinks]{hyperref}
\usepackage[all]{hypcap}
\setcounter{tocdepth}{2}
\hypersetup{
	colorlinks=true,
	urlcolor=black,
	linkcolor=black,
	citecolor=black,
	plainpages=false,
	bookmarksopen=true,
	pdfauthor={\Authors},
	pdftitle={\Title}}

\def\chapterautorefname{Chapter}
\def\appendixautorefname{Appendix}
\def\sectionautorefname{Section}
\def\subsectionautorefname{Section}
\def\figureautorefname{Figure}
\def\tableautorefname{Table}
\def\listingautorefname{Listing}

% source code
\usepackage{xcolor}
\usepackage{textcomp}
\usepackage{listings}
\definecolor{source}{gray}{0.9}
\lstset{
	language={},
	% characters
	tabsize=3,
	upquote=true,
	escapechar={!},
	keepspaces=true,
	breaklines=true,
	alsoletter={\#:},
	breakautoindent=true,
	columns=fullflexible,
	showstringspaces=false,
	basicstyle=\footnotesize\sffamily,
	% background
	frame=single,
    framerule=0pt,
	backgroundcolor=\color{source},
	% numbering
	numbersep=5pt,
	numberstyle=\tiny,
	numberfirstline=true,
	% captioning
	captionpos=b,
	% formatting (html)
	moredelim=[is][\textbf]{<b>}{</b>},
	moredelim=[is][\textit]{<i>}{</i>},
	moredelim=[is][\color{red}\uwave]{<u>}{</u>},
	moredelim=[is][\color{red}\sout]{<del>}{</del>},
	moredelim=[is][\color{blue}\underline]{<ins>}{</ins>}}
\newcommand{\ct}{\lstinline[backgroundcolor=\color{white},basicstyle=\footnotesize\ttfamily]}
\newcommand{\lct}[1]{{\small\tt #1}}

% tikz
% \usepackage{tikz}
% \usetikzlibrary{matrix}
% \usetikzlibrary{arrows}
% \usetikzlibrary{external}
% \usetikzlibrary{positioning}
% \usetikzlibrary{shapes.multipart}
% 
% \tikzset{
% 	every picture/.style={semithick},
% 	every text node part/.style={align=center}}

% proof-reading
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\newcommand{\ra}{$\rightarrow$}
\newcommand{\ugh}[1]{\textcolor{red}{\uwave{#1}}} % please rephrase
\newcommand{\ins}[1]{\textcolor{blue}{\uline{#1}}} % please insert
\newcommand{\del}[1]{\textcolor{red}{\sout{#1}}} % please delete
\newcommand{\chg}[2]{\textcolor{red}{\sout{#1}}{\ra}\textcolor{blue}{\uline{#2}}} % please change
\newcommand{\chk}[1]{\textcolor{ForestGreen}{#1}} % changed, please check

% comments \nb{label}{color}{text}
\newboolean{showcomments}
\setboolean{showcomments}{true}
\ifthenelse{\boolean{showcomments}}
	{\newcommand{\nb}[3]{
		{\colorbox{#2}{\bfseries\sffamily\scriptsize\textcolor{white}{#1}}}
		{\textcolor{#2}{\sf\small$\blacktriangleright$\textit{#3}$\blacktriangleleft$}}}
	 \newcommand{\version}{\emph{\scriptsize$-$Id$-$}}}
	{\newcommand{\nb}[2]{}
	 \newcommand{\version}{}}
\newcommand{\rev}[2]{\nb{Reviewer #1}{red}{#2}}
\newcommand{\ab}[1]{\nb{Alexandre}{blue}{#1}}
\newcommand{\vp}[1]{\nb{Vanessa}{orange}{#1}}
\newcommand{\jp}[1]{\nb{Juan Pablo}{green}{#1}}


% graphics: \fig{position}{percentage-width}{filename}{caption}
\DeclareGraphicsExtensions{.png,.jpg,.pdf,.eps,.gif}
\graphicspath{{figures/}}
\newcommand{\fig}[4]{
	\begin{figure}[#1]
		\centering
		\includegraphics[width=#2\textwidth]{#3}
		\caption{\label{fig:#3}#4}
	\end{figure}}

\newcommand{\largefig}[4]{
	\begin{figure*}[#1]
		\centering
		\includegraphics[width=#2\textwidth]{#3}
		\caption{\label{fig:#3}#4}
	\end{figure*}}
	
\newcommand{\wrapfig}[5]{	
\begin{wrapfigure}{#1}{#2\textwidth}
  \begin{center}
    \includegraphics[width=#3\textwidth]{#4}
  \end{center}
  \caption{\label{fig:#4}#5}
\end{wrapfigure}}

% abbreviations
\newcommand{\ie}{\emph{i.e.,}\xspace}
\newcommand{\eg}{\emph{e.g.,}\xspace}
\newcommand{\etc}{\emph{etc.}\xspace}
\newcommand{\etal}{\emph{et al.}\xspace}

% lists
\newenvironment{bullets}[0]
	{\begin{itemize}}
	{\end{itemize}}

\newcommand{\seclabel}[1]{\label{sec:#1}}
\newcommand{\secref}[1]{Section~\ref{sec:#1}}
\newcommand{\figlabel}[1]{\label{fig:#1}}
\newcommand{\figref}[1]{Figure~\ref{fig:#1}}
\newcommand{\tablabel}[1]{\label{tag:#1}}
\newcommand{\tabref}[1]{Table~\ref{fig:#1}}


%Specialized macros
\newcommand{\hapao}{Hapao\xspace}
\newcommand{\Hapao}{Hapao\xspace}
\pagenumbering{arabic}

\begin{document}

\title{\Title}
%\titlerunning{\TitleShort}

\author{\Authors\\[3mm]
Department of Computer Science (DCC)\\ University of Chile, Santiago, Chile\\[1 ex]
} 
%\authorrunning{\AuthorsShort}

\maketitle

%\emph{This paper makes use of colored figures. Though colors are not mandatory for full understanding, we recommend  the use of a colored printout.}

\begin{abstract}
%	What's the problem.
Code profilers estimate the amount of time spent in each method by regularly sampling the method call stack. 
%One of the main advantage of execution sampling is the relatively low overhead it incurs. 
However, execution sampling is fairly inaccurate.
%	Why is the problem a problem?
This inaccuracy may gives a false sense of CPU time distribution and prevents profilers from being used to estimate the code coverage.
%Under optimal condition, the execution sampling report only half the methods that actually executed, and so, both on Pharo and VisualWorks Smalltalk.

%	What's the surprising idea?
Multiplying the execution of the code to be profiled increases the profiler accuracy.
We shows that the relation between the number of iterations and the precision of the profiler follows a logarithm curve. 
%	What's the consequence?
We propose a statistical model to determine the right amount of iterations to reach a particular ration of reported methods. We use this model to estimate and increase the profiling accuracy.
\end{abstract}

%: % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Introduction}\seclabel{introduction}

Precisely determining what is happening during the execution of a program is difficult. Modern programming environments provide code execution profilers to report on the execution behavior. Code execution profilers are particularly useful at estimating where the CPU (or the virtual machine) is spending time on. 

Precisely determining the CPU consumption time share for each method involved in a computation is challenging. Inspecting the execution of a program has an impact on the execution itself. Execution sampling is a technique commonly employed when profiling code execution. It is relatively accurate and it keeps the impact on the executed program relatively low. As a consequence execution sampling is used in the large majority of code execution profilers.

Execution sampling behaves relatively well on long and focused program execution, however, it is fairly inaccurate for short program execution. This is a well known problem that software engineer address by executing the same code multiple times~\cite{Wils00a}. This artificial increase of the execution time produces a gain in the profiling accuracy. What is however unclear, is the amount of necessary iterations to reach a satisfactory profiling. 

The research question addressed in this paper is: \emph{Can the number of multiple executions be related to the accuracy of the execution sampling?}

We answer this question by carefully measuring the amount of reported methods in a profile. By executing multiple times the code to profile, we measure the gain in reported method. We determined that this gain follows a logarithmic curve. By establishing a regression model, we are able to estimate the profiling precision based on a small number of execution samples.

%The research questions addressed in this paper are:
%\begin{itemize}
%\item[A-] \emph{Can we measure the impact of repeatedly executing the same piece of code when sampling its execution?}
%\item[B-] \emph{Can the number of multiple executions be related to the accuracy of the execution sampling?}
%\end{itemize}

%Contributions are:
%\begin{itemize}
%\item We identify serious limitations in the way execution sampling-based profiling is realized in Visualworks and Pharo.
%\item We 
%\end{itemize}


We first illustrate the impact on multiple execution on a number of Smalltalk applications (\secref{executionSampling}). 
Subsequently, we measure this impact and establish a statistical model for it (\secref{measuringTheGain}).
We then review the related work (\secref{relatedwork}) before concluding (\secref{conclusion}).

%: % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Code Execution Sampling} \seclabel{executionSampling}

%=====
\subsection{Profiling example}


Consider the Smalltalk expression \ct{XMLDOMParser parse: xmlString.} Evaluating this expression returns an abstract syntax tree describing the provided xml content. Evaluating this expression with an arbitrary XML content takes 156 ms on our machine\footnote{MacBook Pro, 8Gb of Ram, 2.26 GHz Intel Core 2 Duo}. 

%Time millisecondsToRun: [  XMLDOMParser parse: (FileStream fileNamed: '/Users/alexandrebergel/Documents/CaseStudy/ArgoUML-0-28-1/src/argouml-documentation/src/docbook-setup/docbook-xsl/xhtml/callout.xsl') contents ].

We profiled the xml parsing using MessageTally, the standard profiler in Pharo, as follows:

\begin{lstlisting}
MessageTally spyOn: [ XMLDOMParser parse: xmlString ]
\end{lstlisting}

Profiling an application increases the execution time. 
The total execution reported by MessageTally is 168 ms. We see an increase of $(168 - 156) / 156 = 7\%$ of the execution time. Lengthening the execution time by 7\% for a time profile is a compromise acceptable in out \vp{our?} situation (\ie non-realtime operation, with a relatively thin interaction with the operating system).

MessageTally reports for the absolute and relative time spent in each method. Consider \ct{XMLTokenizer>>nextTag}, MessageTally reveals it takes 15\% of the total execution:

\begin{lstlisting}
15.5% {26ms} XMLTokenizer>>nextTag
  10.1% {17ms} SAXDriver>>handleStartTag:attributes:namespaces:
  3.6% {6ms} XMLTokenizer>>nextEndTag
\end{lstlisting}

The method \ct{nextTag} is reported to call two other methods, \ct{handleStartTag:attributes:namespaces} and \ct{nextEndTag}. The source code \ct{nextTag} is quite complex, and it sends exactly 15 different messages. However, only two of them are reported by MessageTally.

About 64 different methods are part of the profile (average from 20 runs). A careful tracing of the xml parsing expression reveals that 258 methods are executed in total. This means that only $0.24 = 24\%$ of the methods involved in parsing an xml content are reported by MessageTally. 

%(1 to: 20) collect: [ :i | 
%	(MessageTally
%			spyOn: [  XMLDOMParser parse: (FileStream fileNamed: '/Users/alexandrebergel/Documents/CaseStudy/ArgoUML-0-28-1/src/argouml-documentation/src/docbook-setup/docbook-xsl/xhtml/callout.xsl') contents ] 
%			reportOtherProcesses: false
%			cutoff: 1 
%			openResultWindow: false 
%			closeAfter: false) allMethodNames size ] .
		
%((Compteur profile: [
%XMLDOMParser parse: (FileStream fileNamed: '/Users/alexandrebergel/Documents/CaseStudy/ArgoUML-0-28-1/src/argouml-documentation/src/docbook-setup/docbook-xsl/xhtml/callout.xsl') contents] inPackagesMatching: 'XML*') allMethods select: #isCovered) size

\fig{h}{0.5}{Ratio}{Ratio between reported methods and executed methods (higher is better).}
%	Ratio 	TimeToRun
%XML	0.41
%ECompletion	0.43	 
%Shout	0.82	6964
%Regex	0.25	76
%Ring	0.27
%Zinc	0.33
%Merlin	0.01	4
%ProfStef	0.28

To verify whether this effect is particular to our particular expression or not, we run a similar experiment on 7 other applications.
We took 7 applications popular applications contained in the standard Pharo image. We profiled the execution of the unit tests for each of them twice, the first time using an execution sampling profiler (MessageTally), and the second time by instrumenting the method (using Compteur~\cite{Berg11d}).
By instrumenting the method, we get an accurate amount of methods involved in the execution. The average of the ratio between reported methods and executed methods for our 8 applications (including the xml parsing) is 0.35. 

Merlin has the lowest ratio: only 1\% of the executed methods are reported by MessageTally. The reason is probably the extremely short execution of the unit tests (4 ms), meaning that less methods will be caught by the profiler (we recall by the sampling is done every milliseconds). 
Shout has the highest ratio (0.82). Shout has the longest execution time (6964 ms). This implies that more methods will be sampled by the profiler. 

The fact that some methods are missed by MessageTally is a direct consequence to execution sampling, the strategy used by most of the code execution profilers.


%=====
\subsection{Execution sampling}
Execution sampling approximates the time spent in an application's methods by periodically stopping a program and recording the collection of methods being executed~\cite{Whal00a}. In VisualWorks and Pharo, the code to profile is executed in a new thread and the profiler runs in a thread at a higher priority~\cite{Berg11d}. 
When the profiling thread is activated, it inspects the runtime method call stack (accessible via the \ct{thisContext} pseudo variable) of the observed thread. Per default, this inspection happens every milliseconds\footnote{In Java systems, the profiling time sampling is usually 10 milliseconds~\cite{Mytk10a}.}. 

Execution sampling has many advantages. Firstly, it has a low impact on the overall execution. In Pharo, a code is between 5\% and 12\% longer to execute when being profiled. This is reasonable in the large majority of the case developed in Pharo (\ie non-realtime application with little dependencies on the operating system). 
Secondly, execution sampling has no impact on the profiled application semantics in the large majority of cases. %The application is expected to have the same behavior if profiled in the majority of cases. An application that intensively use the language reflective facilities may be perturbed by the regular sampling exercised with the thread launched by the profiler. However, this is hardly the case in practice. 
%Thirdly, almost no configuration is required for the profiling to be carried out. Contrary to instrumentation-based profiling, no scope for the instrumentation has to be defined.

%In contrast to its numerous advantages, execution sampling remains particularly shy on the analyze one can carry out with it. 

However, as we have previously shown, sampling an execution can be quite inaccurate and incomplete. 

%=====
\subsection{Increasing the execution time}

%MessageTally in Pharo samples the stack every millisecond. It often happens that methods with a short execution time are not reported by the profiler. This is a well known problem. 

It is common to artificially increase the execution time to gain in accuracy when sampling the execution. This is easily done by running multiple times the code to profile. Putting the expression we are interested in a loop makes the profiling more precise:

\begin{lstlisting}
MessageTally spyOn: [  
	10 timesRepeat: [ XMLDOMParser parse: xmlString ] ]
\end{lstlisting}

The consumption of \ct{nextTag} is now reported as:

\begin{lstlisting}
15.6% {260ms} XMLTokenizer>>nextTag
  8.1% {135ms} SAXDriver>>handleStartTag:attributes:namespaces:
  3.1% {51ms} XMLTokenizer>>nextEndTag
  2.0% {33ms} XMLTokenizer>>nextAttributeInto:namespaces:
\end{lstlisting}

The call to \ct{nextAttributeInto:namespaces:} is now revealed. By repeatedly executing the same expression, the total execution time increases, enabling more methods to be detected during a sampling. 132 methods are now reported by MessageTally. This makes the ratio goes from 0.24 to 0.51.

%(1 to: 5) collect: [ :i | 
%	(MessageTally
%			spyOn: [  10 timesRepeat: [XMLDOMParser parse: (FileStream fileNamed: '/Users/alexandrebergel/Documents/CaseStudy/ArgoUML-0-28-1/src/argouml-documentation/src/docbook-setup/docbook-xsl/xhtml/callout.xsl') contents] ] 
%			reportOtherProcesses: false
%			cutoff: 1 
%			openResultWindow: false 
%			closeAfter: false) allMethodNames size ] .


\fig{h}{0.5}{RatioAfter10Loops}{Ratio of reported methods with a loop of 10 iterations (higher is better).}

\figref{RatioAfter10Loops} shows the applications for which we repeated 10 times their corresponding unit tests. The effect of the loop is significant. The average ratio of reported methods is now 0.58. 

We have arbitrarily chosen a loop of 10 iterations. For some applications, the impact of using 10 iterations is stronger than for others. For example, sampling 10 executions of the unit tests of Regex reports 66\% of the used methods, whereas it was only 25\% with a single execution. The following section discuss the impact of multiple executions.

%: % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Measuring the gain} \seclabel{measuringTheGain}
 
%=====
\subsection{Regression line}

To get a better understanding of the impact of multiple executions, the following expression successively profiles the xml parser:

\begin{lstlisting}
#(1 11 21 31 41 51 ... 241) do: [ :numberOfIterations |
	MessageTally spyOn: [  
		numberOfIterations 
			timesRepeat: [ XMLDOMParser parse: xmlString ] ] ]
\end{lstlisting}

The effect of using \ct{numberOfIterations timesRepeat: [ ... ]} artificially increase the execution time of the expression we are interested in. Naturally, we assume all the executions are the same. The code we gave is a simplified version of how we actually measured the profiles. we make sure that before profiling we properly clean the memory by running multiple times the garbage collector.

%#(1 11 21 31 41 51 61 71 81 91 101 111 121 131 141 151 161 171 181) collect: [:iterations | 
%		10 timesRepeat: [ Smalltalk garbageCollect ].
%		Object new; new; new; new.
%		10 timesRepeat: [ Smalltalk garbageCollect ].
%
%		((MessageTally
%				spyOn: [  iterations timesRepeat: [XMLDOMParser parse: (FileStream fileNamed: '/Users/alexandrebergel/Documents/CaseStudy/ArgoUML-0-28-1/src/argouml-documentation/src/docbook-setup/docbook-xsl/xhtml/callout.xsl') contents] ] 
%				reportOtherProcesses: false
%				cutoff: 1 
%				openResultWindow: false 
%				closeAfter: false) allMethods select: [:m | 'XML*' match: m methodClass theNonMetaClass category]) size ].

\fig{h}{0.5}{IterationEvolution}{Evolution of the ratio against multiple execution.}

\figref{IterationEvolution} shows our measurements. Horizontally is the number of iterations for the xml parsing expression. The number of times it is executed goes from 1 to 241, with an increment of 10. Vertically is the ratio of reported methods. It goes from 0.24 and tops at 0.81. Each cross corresponds to a measurement \textit{iteration, ratio)}.

The trendline is indicated with a continuous line and has a logarithmic shape. The regression equation given by common statistical tools has the pattern $y = a~ln(x) + b$. In the case of our xml parsing, $a = 0.0974$ and $b = 0.2918$. The associated ``test of goodness of fit'', $R^2$, is 0.9514. A value close to 1 means a good fit, \ie the equation matches the observed data. We will gives an accurate definition of $R^2$ later on (\secref{rSquared}).

\fig{h}{0.5}{IterationEvolutionForApplications}{Evolution of the ratio.}
We repeat the same analysis on our applications (\figref{IterationEvolutionForApplications}). All the regression lines are logarithmic curves, with a $R^2$ over 0.89. 

%=====
\subsection{Determining $a$ and $b$}

We have seen that the regression line follows the pattern $y = a~ln(x) + b$. For a given set of iterations ($x$), we can determine the method ratio of the profiling ($y$) assuming that we know about $a$ and $b$. 

As our measurement show, the value of $a$ and $b$ are proper to the piece of code to be profiled. Since we are interested in predicting the amount of iterations for a given ratio, we need to determine $a$ and $b$. 

First, we need to get rid of the logarithm by writing $X = ln(x)$ and $Y = y$. The equation becomes $Y = a X + b$, which is much simpler to reason about. For a given set of $(X, Y)$ plots, $a$ and $b$ are easily determined using the standard statical books:

\[
b = \frac{SS_{XY}}{SS_{XX}} ~~~~~ a = \overline{Y} - b~\overline{Y}
\]

where 

\[
\textit{SS}_{XY} = \sum XY - \frac{(\sum X)(\sum Y)}{n}~~~~~~\textit{SS}_{XX} = \sum X^2 - \frac{(\sum X)^2}{n}
\]

We further have $n$ is the number of samples; 
\textit{SS} stands for ``sum of squares'';
$\overline{X}$ is the average of all the $X$ values;
$\overline{Y}$ is the average of all the $Y$ values.

Using our example of xml parsing, we already had 

\begin{center}
\begin{tabular}{|c|c|}
\hline
iterations ($x$) & ratio ($y$) \\\hline
31		& 0.61 \\
61		& 0.72\\
91		& 0.7\\
121		& 0.78\\
\hline
\end{tabular}
\end{center}

The values of $X = ln(x)$ are therefore \textit{\{ln(31), ln(61), ln(91), ln(121)\}}.
By applying the formulas given above, we find $a = 0.1097$ and $b = 0.2404$. 

The regression equation for the xml parsing is therefore $y = 0.1097~ln(x) + 0.2404$. This equation is pretty close to have we have found in the previous section.

We can then deduce:
\[
x = e^{\frac{y-b}{a}}
\]

If we wish to obtain a ratio of 0.8 of our profile, then we need $e^{\frac{0.8 - 0.2404}{0.1097}} = 164$ iterations. Our measurement shows that the 0.8 ratio threshold is reached after 151 iterations.

%=====
\subsection{How confident are we?} \seclabel{rSquared}

%http://en.wikipedia.org/wiki/Coefficient_of_determination

The previous section gives a model that binds the amount of code iterations with the ratio of reported methods during a profile. We use our model to ``predict'' the value of the ratio for a given amount of iterations.

One piece in our analyze is however missing, which is about the trust we can give in our prediction. In statistics, the coefficient of determination $R^2$ tells about the amount of variability in a data set. More variable a data set is, higher $R^2$ is.



%: % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{VisualWorks and Pharo}\seclabel{comparison}

The measurement given above have been realized in Pharo Smalltalk with a non-jitted virtual machine. To verify whether the model we have previously described is particular to Pharo or not, we take VisualWorks Smalltalk\footnote{\url{http://www.cincomsmalltalk.com}}, a popular Smalltalk dialect, and run a similar set of experiences.

The executing environment and profiler of VisualWork (VW) differ from the one of Pharo on two essential points:

\begin{itemize}
\item The virtual machine of VW is significantly faster than the non-jitted one of Pharo. 
\item In VW, the sampling period is randomly selected in a range $[1 , 32]$ milliseconds. Using a random sampling period leads to an increase of precision~\cite{Mytk10a}. In Pharo the sampling period is fixed.
\end{itemize}

\fig{h}{0.5}{IterationEvolutionOnVW}{Evolution of the ratio on VisualWorks.}

\figref{IterationEvolutionOnVW} the evolution of the ratio for 4 applications. We tried two industrial applications, noted \ct{X} and \ct{Y}, and two open-source applications, Mondrian and \chg{OSkStream}{OSkSubStream}. These four experiences confirm our previous finding: the ratio between profiled methods and executed methods follows a logarithmic curve. Our results strongly suggest that the performance of the virtual machine, the just-in-time compiler and the random sampling do not impact the ratio of reported methods in a sampling-based profile.

These four experiences confirm our previous finding: the ratio between profiled methods and executed methods follows a logarithmic curve. Our results strongly suggest that the performance of the virtual machine, the just-in-time compiler and the random sampling do not impact the ratio of reported methods in a sampling-based profile. 


%: % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Related work}\seclabel{relatedwork}

Extracting accurate profiles from a software execution is challenging. \vp{There is?}A number of works to increase the accuracy of profilers without losing any information about the execution and without increasing a substantial execution overhead. \vp{I there is something missing for this sentense to have meaning}

%This section discusses how the sampling based and instrumentation based profilers tried to increase the accuracy and minimize the execution overhead.

%=====
%\paragraph{Sampling-based profiling}

Several techniques have been proposed to increase the accuracy and reduce the overhead of execution sampling.

%(i) using variable sampling period time~\cite{Myth10a}, (ii)counting byte-code instead of waiting for an elapsed time ~\cite{Bind06a}, (iii)increasing the sampling period by using multiple markers~\cite{Fischmeister:2010:SPE:1755888.1755908}, (iv) identify calling context without walking the entire stack and distinguish between frequently-executed and long running methods~\cite{Whaley:2000:PSP:337449.337483}.

%\ab{Write a paragraph for each of these techniques. Each paragraph should summarize what their idea is, and then compare it with what we have done, or even better, say whether their technique is applicable in our case}

%\vp{Mytkowicz, Diwan, Hauswirth, Sweeney evaluate 4 profilers for Java, exposing that they do not match in their evaluation to identify the hot methods, candidates to optimize. They then propose a more accurate profiler that collects execution information using random sampling and does not suffer from the above problems.}

%Variable sampling period time~\cite{Mytk10a}

Mytkowicz, Diwan, Hauswirth, Sweeney evaluate 4 of profilers for Java, exposing that they do not match in their evaluation to identify the hot methods, candidates to optimize. They then propose a more accurate profiler that collects samples randomly and it does not suffer from the above problems ~\cite{Mytk10a}. 

Fischmeister and Ba ~\cite{Fischmeister:2010:SPE:1755888.1755908} propose theorems to determine the sampling period in different scenarios, and heuristics to extend the sampling period to reduce the overhead.

Our approach, however, we can see that even if we use random sampling or a determinated sampling period, the ratio between reported methods and executed methods is inaccurate.

%\vp{Review this please!} Our approach, however, is different as we do not focus to find the hot methods but for the profiler to identify more methods in the sampling. We can see that even if we do not use random sampling, by increasing the number of iterations on the profiler, we still can obtain a larger ratio between reported methods and executed methods.

%strategy using markeds showed how to increase the sampling period by using multiple markers. However, this method had limitation in that overusing markers did not pay off as much as we expected in the long run.
%A marker can be a system element such as the program counter, very useful, because a vertex in the control-flow graph is a basic block in the source code. Besides, a marker can also be a newly introduced variable solely used for the purpose of monitoring the software.

Whaley present a sampling-based profiler for Java Virtual Machines. It is able to correctly identify calling context without walking the entire stack and distinguish between frequently-executed and long running methods. Also, the profile data is extremely accurate.\cite{Whaley:2000:PSP:337449.337483}. 

%\vp{Whaley present a sampling-based profiler for Java Virtual Machines. It is able to correctly identify calling context without walking the entire stack and distinguish between frequently-executed and long running methods. Also, the profile data is extremely accurate.\cite{Whaley:2000:PSP:337449.337483}. }


%It is not only efficient enough to be used continuously in a production environment (2-4\% slowdown for most applications) but is also surprisingly accurate in the data that it collects (typically >= 90\% accurate).

Binder present his sampling-based profiling framework for Java ~\cite{Binder:2006:PAS:1133013.1133016} to implement custom profiling agents in pure Java. It is a sampling based on byte-code instruction counting and it offers a good trade-off between high accuracy of profiles and reasonable overhead. The features of Binder profiler can improve our overall impact. In this sense the ratio between profiled methods and executed methods could be more deterministic.


%The key problem in sampling-based execution monitoring is to increase the sampling period. Notorious cases, such as programs with short conditional branches, will result in a low sampling period, if the resolution needs to be given at the granularity of basic blocks. ~\cite{Thomas:2011:LOS:1967677.1967692}
%Binder discovered that sampling the method call stack after a particular amount of executed bytecodes makes profile significantly more accurate.

%=====
%\paragraph{Instrumentation-based profiling}

%Instrumentation-based profilers insert instrumentation code into the target program to collect runtime information. \chg{It}{The major disadvantage of instrumenting the profiled code is that it} introduces considerable overhead to the execution of the program. Researchers have proposed several methods to reduce the cost of instrumentation overhead:  (i) 

Arnold and Ryder ~\cite{Arno01a} present a framework to perform instrumentation sampling. Their framework perform a code duplication, and counter-based sampling to switch between instrumented (copy) and no-instrumented code. This reduce the overhead but need to do an expensive instrumentation first.

%\vp{Arnold and Ryder~\cite{Arno01a}. present a framework to perform instrumentation sampling. Their framework perform a code duplication, and counter-based sampling to switch between instrumented (copy) and no-instrumented (original) code. This reduce the overhead but needs to do an expensive instrumentation first.}

%a code duplication, using a compiler-inserted counter-based sampling to switch between instrumented and non-instrumented code in a controlled, fine-grained manner ~\cite{Arno01a}.

%\jp{I am not sure about Instrumentation-based profiling, because we are talking about the hidden face of sampling-based profilers...}

%In our case we run many times an execution scenario in order to increases the profiler accuracy. But have a big impact on the overall execution, this approach is not useful to real time systems.

%However, we propose in order to improve profiler accuracy in our case the execution scenario is run many times, but this has a big impact on the overall execution overhead. Then this approach is not useful for real time systems for example.

In order to improve profiler accuracy, we propose to execute the scenario a larger number of times, allowing the profiler to catch more methods. However this has a big impact on the profiler overall execution overhead. For this, our approach is not useful for real time systems, for example.

%: % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Conclusion \& Future Work}\seclabel{conclusion}

The difficulty to properly monitor an application execution imposes a severe compromise between what information can be extracted and the cost to obtain it. In this paper we have motivated and measured a simple way to increase the accuracy of profiles based on execution sampling.

As future work, we plan to integrate our model into Kai~\cite{Berg11f}, a fully fledged code execution profiler.


\paragraph{Acknowledgments} We thanks Johan Fabry and Romain Robbes for the discussion we had on the statistical part.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

%\appendix
%\section{Complete Blueprint}

%{\small
\bibliographystyle{plain}
\bibliography{scg}
%\bibliography{hapao}
%}
\end{document}

%: % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
